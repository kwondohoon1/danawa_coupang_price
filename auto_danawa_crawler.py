# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Mq30bavMMGFxHgWOOCEJpdgMXmn4L3i
"""

import os, re, io, time, traceback, requests, asyncio, aiohttp
from pathlib import Path
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# ===============================================
# âš¡ Danawa ì¿ íŒ¡ ì •ì +ë™ì  ë³‘í•© ë²„ì „
# ===============================================

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
TARGET_COLS = ["ì¿ íŒ¡", "ì¿ íŒ¡ì™€ìš°", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"]

WORKDIR = Path(os.getenv("GITHUB_WORKSPACE", os.getcwd()))
INPUT_PATH = WORKDIR / "ìƒí’ˆì½”ë“œëª©ë¡.xlsx"
OUTPUT_PATH = WORKDIR / f"danawa_ì¿ íŒ¡_ì •í™•ë²„ì „_{datetime.now():%Y%m%d_%H%M}.xlsx"


# -----------------------------
# ìœ í‹¸
# -----------------------------
def _only_digits(s): return re.sub(r"[^\d]", "", s or "")


# -----------------------------
# Selenium ë“œë¼ì´ë²„ (ë™ì ìš©)
# -----------------------------
def get_driver():
    from webdriver_manager.chrome import ChromeDriverManager
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-gpu")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)


# -----------------------------
# ì¿ íŒ¡ì™€ìš°ê°€ê²© (ë™ì )
# -----------------------------
def fetch_wow_prices_selenium(driver, pcodes):
    wow_map = {}
    for pcode in pcodes:
        try:
            url = f"https://prod.danawa.com/info/?pcode={pcode}"
            driver.get(url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#lowPriceCompanyArea"))
            )
            time.sleep(1.0)
            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")
            text = soup.get_text(" ", strip=True)
            match = re.search(r"ì™€ìš°.?í• ì¸.?ê°€\s*([\d,]+)\s*ì›", text)
            if match:
                wow_map[pcode] = match.group(1).replace(",", "")
        except Exception:
            continue
    return wow_map


# -----------------------------
# ì •ì  HTML íŒŒì‹± (requests)
# -----------------------------
def parse_static_product_html(html: str, pcode: str) -> dict:
    soup = BeautifulSoup(html, "html.parser")
    row = {
        "ìƒí’ˆì½”ë“œ": pcode,
        "ìƒí’ˆëª…": "ì´ë¦„ì—†ìŒ",
        "ì¿ íŒ¡": "X",
        "ì¿ íŒ¡ì™€ìš°": "X",
        "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€": "X",
    }

    # ìƒí’ˆëª…
    tag = soup.select_one("meta[property='og:title']")
    if tag and tag.get("content"):
        row["ìƒí’ˆëª…"] = tag["content"].strip()
    else:
        alt = soup.select_one(".prod_tit, h3.tit")
        if alt:
            row["ìƒí’ˆëª…"] = alt.get_text(strip=True)

    # ê°€ê²©ë“¤
    for li in soup.select("ul.list__mall-price > li.list-item"):
        text = li.get_text(" ", strip=True)
        logo = li.select_one(".box__logo, .box__logo-wrap .box__logo")
        if not logo or "ì¿ íŒ¡" not in text:
            continue
        prices = [int(_only_digits(p.get_text(strip=True))) for p in li.select(".text__num, .price_num strong, .txt_prc strong, .prc strong") if _only_digits(p.get_text(strip=True))]
        if not prices:
            continue
        price = min(prices)
        # ì™€ìš°ëŠ” Seleniumì—ì„œ ë³„ë„ ë³´ì •
        if "ì¹´ë“œ" in text or "ì²­êµ¬" in text or "í• ì¸" in text:
            row["ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"] = str(price)
        else:
            row["ì¿ íŒ¡"] = str(price)

    return row


def fetch_static_prices(codes):
    results = []
    with requests.Session() as session:
        session.headers.update(headers)
        for idx, pcode in enumerate(codes, start=1):
            try:
                url = f"https://prod.danawa.com/info/?pcode={pcode}"
                print(f"({idx}/{len(codes)}) {pcode} ì •ì  ìˆ˜ì§‘ ì¤‘...")
                r = session.get(url, timeout=10)
                row = parse_static_product_html(r.text, pcode)
                results.append(row)
            except Exception as e:
                print(f"[ì—ëŸ¬] {pcode}: {e}")
                results.append({"ìƒí’ˆì½”ë“œ": pcode, "ìƒí’ˆëª…": "ì—ëŸ¬", "ì¿ íŒ¡": "X", "ì¿ íŒ¡ì™€ìš°": "X", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€": "X"})
    return results


# -----------------------------
# ì‹¤í–‰
# -----------------------------
def run_crawler():
    try:
        print(f"[{datetime.now()}] Danawa í¬ë¡¤ë§ ì‹œì‘")
        df = pd.read_excel(INPUT_PATH)
        codes = df["ìƒí’ˆì½”ë“œ"].dropna().astype(str).str.replace(r"\.0$", "", regex=True).tolist()

        # 1ï¸âƒ£ ì •ì  ìˆ˜ì§‘ (ìƒí’ˆëª…, ì¿ íŒ¡, ì¹´ë“œí˜œíƒê°€)
        static_results = fetch_static_prices(codes)
        results_map = {r["ìƒí’ˆì½”ë“œ"]: r for r in static_results}

        # 2ï¸âƒ£ ì™€ìš°ê°€ê²©ë§Œ Seleniumìœ¼ë¡œ ë™ì  ë³´ì •
        need_wow = [r["ìƒí’ˆì½”ë“œ"] for r in static_results if r.get("ì¿ íŒ¡ì™€ìš°") in ("X", "", None)]
        print(f"ğŸŸ¡ ì™€ìš°ê°€ê²© ë³´ì • ëŒ€ìƒ {len(need_wow)}ê°œ")

        if need_wow:
            driver = get_driver()
            wow_map = fetch_wow_prices_selenium(driver, need_wow)
            driver.quit()
            for code, wprice in wow_map.items():
                results_map[code]["ì¿ íŒ¡ì™€ìš°"] = wprice

        # 3ï¸âƒ£ ìµœì €ê°€ ê³„ì‚°
        df_out = pd.DataFrame(list(results_map.values())).fillna("X")
        for col in ["ì¿ íŒ¡", "ì¿ íŒ¡ì™€ìš°", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"]:
            df_out[col] = pd.to_numeric(df_out[col], errors="coerce")
        df_out["ìµœì €ê°€"] = df_out[["ì¿ íŒ¡", "ì¿ íŒ¡ì™€ìš°", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"]].min(axis=1).map(lambda x: "X" if pd.isna(x) else str(int(x)))

        # 4ï¸âƒ£ ì—‘ì…€ ì €ì¥ + ìƒ‰ìƒ í‘œì‹œ
        df_out.to_excel(OUTPUT_PATH, index=False, engine="openpyxl")
        wb = load_workbook(OUTPUT_PATH)
        ws = wb.active
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        header = [cell.value for cell in ws[1]]
        for idx, name in enumerate(header, start=1):
            if name in TARGET_COLS:
                for r in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=idx, max_col=idx):
                    for cell in r:
                        cell.fill = yellow
        wb.save(OUTPUT_PATH)

        print(f"âœ… ê²°ê³¼ íŒŒì¼ ìƒì„± ì™„ë£Œ: {OUTPUT_PATH}")

    except Exception as e:
        print(traceback.format_exc())
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    run_crawler()
