# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Mq30bavMMGFxHgWOOCEJpdgMXmn4L3i
"""

import os, re, io, time, tempfile, traceback
from pathlib import Path
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# ===============================================
# ⚡ Danawa 쿠팡
# ===============================================

TARGET_COLS = ["쿠팡", "쿠팡와우", "쿠팡카드혜택가"]

# GitHub Actions / 로컬 모두 호환되도록 작업 경로 자동 설정
WORKDIR = Path(os.getenv("GITHUB_WORKSPACE", os.getcwd()))
INPUT_PATH = WORKDIR / "상품코드목록.xlsx"
OUTPUT_PATH = WORKDIR / f"danawa_쿠팡_정확버전_{datetime.now():%Y%m%d_%H%M}.xlsx"

def _only_digits(s): return re.sub(r"[^\d]", "", s or "")

def get_driver():
    from webdriver_manager.chrome import ChromeDriverManager
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

def parse_with_selenium(driver, pcode):
    url = f"https://prod.danawa.com/info/?pcode={pcode}"
    row = {"상품코드": pcode, "상품명": "이름없음", "쿠팡": "X", "쿠팡와우": "X", "쿠팡카드혜택가": "X"}
    try:
        driver.get(url)
        WebDriverWait(driver, 20).until(lambda d: d.execute_script("return document.readyState") == "complete")
        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, "#lowPriceCompanyArea")))
        for _ in range(6):
            driver.execute_script("window.scrollBy(0, 500);")
            time.sleep(0.8)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        title_tag = soup.select_one("meta[property='og:title']")
        if title_tag and title_tag.get("content"):
            row["상품명"] = title_tag["content"].strip()
        else:
            alt = soup.select_one(".prod_tit, h3.tit")
            if alt:
                row["상품명"] = alt.get_text(strip=True)

        for li in soup.select("ul.list__mall-price > li.list-item"):
            txt = li.get_text(" ", strip=True)
            prices = [int(_only_digits(p.get_text(strip=True))) for p in li.select(".text__num, .price_num strong, .txt_prc strong, .prc strong") if _only_digits(p.get_text(strip=True))]
            if not prices:
                continue
            price = min(prices)
            logo = li.select_one(".box__logo, .box__logo-wrap .box__logo")
            if not logo:
                continue
            is_coupang = "쿠팡" in (logo.get("aria-label") or "")
            img = logo.select_one("img[alt]")
            if img and "쿠팡" in img.get("alt", ""):
                is_coupang = True
            if not is_coupang:
                continue

            if "와우" in txt or "WOW" in txt.upper():
                row["쿠팡와우"] = str(price)
            elif any(k in txt for k in ["카드", "청구", "할인", "삼성", "롯데", "하나", "현대"]):
                row["쿠팡카드혜택가"] = str(price)
            else:
                row["쿠팡"] = str(price)
        return row

    except Exception as e:
        print(f"[오류] {pcode}: {e}")
        return row

def run_requests_crawler():
    try:
        print(f"[{datetime.now()}] Danawa 정확버전 시작")
        df = pd.read_excel(INPUT_PATH)
        codes = df["상품코드"].dropna().astype(str).tolist()
        driver = get_driver()

        results = []
        for idx, code in enumerate(codes, start=1):
            print(f"({idx}/{len(codes)}) {code} 크롤링 중...")
            row = parse_with_selenium(driver, code)
            results.append(row)

        driver.quit()
        df_out = pd.DataFrame(results).fillna("X")
        nums = pd.DataFrame({
            "쿠팡": pd.to_numeric(df_out["쿠팡"], errors="coerce"),
            "쿠팡와우": pd.to_numeric(df_out["쿠팡와우"], errors="coerce"),
            "쿠팡카드혜택가": pd.to_numeric(df_out["쿠팡카드혜택가"], errors="coerce"),
        })
        df_out["최저가"] = nums.min(axis=1).map(lambda x: "X" if pd.isna(x) else str(int(x)))
        df_out.to_excel(OUTPUT_PATH, index=False)

        wb = load_workbook(OUTPUT_PATH)
        ws = wb.active
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        header = [cell.value for cell in ws[1]]
        for idx, name in enumerate(header, start=1):
            if name in TARGET_COLS:
                for r in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=idx, max_col=idx):
                    for cell in r:
                        cell.fill = yellow
        wb.save(OUTPUT_PATH)

        print(f"✅ 결과 파일 생성: {OUTPUT_PATH}")
    except Exception as e:
        print(traceback.format_exc())
        print(f"❌ 오류 발생: {e}")

if __name__ == "__main__":
    run_requests_crawler()
