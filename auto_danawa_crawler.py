# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Mq30bavMMGFxHgWOOCEJpdgMXmn4L3i
"""

import os, re, io, tempfile, traceback, asyncio, aiohttp, time, codecs
from pathlib import Path
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from selenium import webdriver
from selenium.webdriver.chrome service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# chardet 있을 때만 사용 (없어도 폴백으로 동작)
try:
    import chardet  # type: ignore
except Exception:
    chardet = None

# -------------------------------------
# 기본 설정
# -------------------------------------
headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
TARGET_COLS = ["쿠팡", "쿠팡와우", "쿠팡카드혜택가"]

WORKDIR = Path(os.getenv("GITHUB_WORKSPACE", os.getcwd()))
INPUT_PATH_XLSX = WORKDIR / "상품코드목록.xlsx"
INPUT_PATH_CSV  = WORKDIR / "상품코드목록.csv"
OUTPUT_PATH     = WORKDIR / f"danawa_쿠팡_결과_{datetime.now():%Y%m%d_%H%M}.xlsx"

def _only_digits(s):
    return re.sub(r"[^\d]", "", s or "")

# -------------------------------------
# CSV 인코딩 감지/폴백
# -------------------------------------
def detect_csv_encoding(path: Path) -> str:
    # BOM 우선 체크
    with open(path, "rb") as f:
        head = f.read(4096)
    if head.startswith(codecs.BOM_UTF8):
        return "utf-8-sig"

    if chardet:
        try:
            enc = chardet.detect(head).get("encoding") or "utf-8"
            return enc
        except Exception:
            pass

    # 폴백: 시도 순서
    for enc in ("utf-8", "utf-8-sig", "cp949", "euc-kr"):
        try:
            head.decode(enc)
            return enc
        except Exception:
            continue
    return "cp949"

# -------------------------------------
# Chrome driver 설정
# -------------------------------------
def get_driver():
    from webdriver_manager.chrome import ChromeDriverManager
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

# -------------------------------------
# 와우가격 Selenium 보정
# -------------------------------------
def fetch_wow_prices_selenium(driver, pcodes):
    wow_map = {}
    for pcode in pcodes:
        try:
            url = f"https://prod.danawa.com/info/?pcode={pcode}"
            driver.get(url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#lowPriceCompanyArea"))
            )
            for _ in range(6):
                driver.execute_script("window.scrollBy(0, 500);")
                time.sleep(0.8)
            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")
            full_text = soup.get_text(" ", strip=True)
            wow_match = re.search(r"와우.?할인.?가\s*([\d,]+)\s*원", full_text)
            if wow_match:
                wow_map[pcode] = wow_match.group(1).replace(",", "")
        except Exception:
            continue
    return wow_map

# -------------------------------------
# HTML 파싱
# -------------------------------------
def _is_coupang_logo(el):
    if el is None:
        return False
    img = el.select_one("img[alt]")
    if img and "쿠팡" in (img.get("alt") or ""):
        return True
    aria = el.get("aria-label") or ""
    if "쿠팡" in aria:
        return True
    text_logo = el.select_one(".text__logo")
    if text_logo and "쿠팡" in text_logo.get_text(strip=True):
        return True
    return False

def _has_wow_hint(text):
    return "와우" in text or "WOW" in text.upper()

def _has_card_hint(text):
    for k in ["카드", "청구", "할인", "삼성", "롯데", "하나", "현대"]:
        if k in text:
            return True
    return False

def _pick_prices_in(el):
    prices = []
    for sel in [".text__num", ".price_num strong", ".txt_prc strong", ".prc strong"]:
        for numel in el.select(sel):
            num = _only_digits(numel.get_text(strip=True))
            if num:
                prices.append(int(num))
    return prices

def parse_product_html(html: str, pcode: str) -> dict:
    soup = BeautifulSoup(html, "html.parser")
    row = {"상품코드": pcode, "상품명": "이름없음", "쿠팡": "X", "쿠팡와우": "X", "쿠팡카드혜택가": "X"}

    tag = soup.select_one("meta[property='og:title']")
    if tag and tag.get("content"):
        row["상품명"] = tag["content"].strip()
    else:
        alt = soup.select_one(".prod_tit, h3.tit")
        if alt:
            row["상품명"] = alt.get_text(strip=True)

    for li in soup.select("ul.list__mall-price > li.list-item"):
        logo = li.select_one(".box__logo, .box__logo-wrap .box__logo")
        if not _is_coupang_logo(logo):
            continue
        txt = li.get_text(" ", strip=True)
        prices = _pick_prices_in(li)
        if not prices:
            continue
        price = min(prices)
        if _has_wow_hint(txt):
            row["쿠팡와우"] = str(price)
        elif _has_card_hint(txt):
            row["쿠팡카드혜택가"] = str(price)
        else:
            row["쿠팡"] = str(price)
    return row

# -------------------------------------
# 파일 로드 (XLSX/CSV 자동)
# -------------------------------------
def read_file_safely():
    try:
        if INPUT_PATH_XLSX.exists():
            return pd.read_excel(INPUT_PATH_XLSX, engine="openpyxl")
        elif INPUT_PATH_CSV.exists():
            enc = detect_csv_encoding(INPUT_PATH_CSV)
            try:
                return pd.read_csv(INPUT_PATH_CSV, encoding=enc)
            except UnicodeDecodeError:
                # 최종 폴백
                for e in ("utf-8", "utf-8-sig", "cp949", "euc-kr"):
                    try:
                        return pd.read_csv(INPUT_PATH_CSV, encoding=e)
                    except Exception:
                        continue
                raise
        else:
            raise FileNotFoundError("입력 파일을 찾을 수 없습니다. 상품코드목록.xlsx 또는 상품코드목록.csv가 필요합니다.")
    except Exception as e:
        raise RuntimeError(f"입력 파일 로드 오류: {e}")

# -------------------------------------
# 비동기 요청 (aiohttp)
# -------------------------------------
async def fetch_one(session, pcode):
    url = f"https://prod.danawa.com/info/?pcode={pcode}"
    try:
        async with session.get(url, timeout=10) as r:
            html = await r.text()
            return parse_product_html(html, pcode)
    except Exception:
        return {"상품코드": pcode, "상품명": "에러", "쿠팡": "X", "쿠팡와우": "X", "쿠팡카드혜택가": "X"}

async def run_async_crawler(codes):
    results_map = {}
    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = [fetch_one(session, c) for c in codes]
        for coro in asyncio.as_completed(tasks):
            row = await coro
            results_map[row["상품코드"]] = row
    return results_map

# -------------------------------------
# 실행 함수
# -------------------------------------
def run_requests_crawler():
    try:
        print(f"[{datetime.now()}] Danawa 크롤링 시작")

        df = read_file_safely()
        if "상품코드" not in df.columns:
            raise ValueError("입력 파일에 '상품코드' 열이 없습니다.")
        codes = df["상품코드"].dropna().astype(str).str.replace(r"\.0$", "", regex=True).str.strip().tolist()

        # 1️⃣ 비동기 크롤링 (HTML 기반)
        results_map = asyncio.run(run_async_crawler(codes))

        # 2️⃣ 와우 가격 빠진 항목 Selenium으로 보정
        need_wow = [c for c, r in results_map.items() if r.get("쿠팡와우") in ("X", "", None)]
        print(f"🟡 와우가격 보정 대상 {len(need_wow)}개")
        if need_wow:
            driver = get_driver()
            wow_map = fetch_wow_prices_selenium(driver, need_wow)
            driver.quit()
            for c, w in wow_map.items():
                results_map[c]["쿠팡와우"] = w

        # 3️⃣ 엑셀 정리 및 저장
        results = [results_map[c] for c in codes if c in results_map]
        df_out = pd.DataFrame(results).fillna("X")
        nums = pd.DataFrame({
            "쿠팡": pd.to_numeric(df_out["쿠팡"], errors="coerce"),
            "쿠팡와우": pd.to_numeric(df_out["쿠팡와우"], errors="coerce"),
            "쿠팡카드혜택가": pd.to_numeric(df_out["쿠팡카드혜택가"], errors="coerce"),
        })
        df_out["최저가"] = nums.min(axis=1).map(lambda x: "X" if pd.isna(x) else str(int(x)))
        df_out.to_excel(OUTPUT_PATH, index=False, engine="openpyxl")

        # 4️⃣ 하이라이트 표시
        wb = load_workbook(OUTPUT_PATH)
        ws = wb.active
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        header = [cell.value for cell in ws[1]]
        for idx, name in enumerate(header, start=1):
            if name in TARGET_COLS:
                for r in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=idx, max_col=idx):
                    for cell in r:
                        cell.fill = yellow
        wb.save(OUTPUT_PATH)
        print(f"✅ 결과 파일 생성 완료: {OUTPUT_PATH}")

    except Exception as e:
        print(traceback.format_exc())
        print(f"❌ 오류 발생: {e}")

# -------------------------------------
# 메인 실행
# -------------------------------------
if __name__ == "__main__":
    run_requests_crawler()
