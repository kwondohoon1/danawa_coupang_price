# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Mq30bavMMGFxHgWOOCEJpdgMXmn4L3i
"""

import os, re, io, tempfile, traceback, asyncio, aiohttp, time
from pathlib import Path
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
TARGET_COLS = ["쿠팡", "쿠팡와우", "쿠팡카드혜택가"]

WORKDIR = Path(os.getenv("GITHUB_WORKSPACE", os.getcwd()))
INPUT_PATH = WORKDIR / "상품코드목록.xlsx"
OUTPUT_PATH = WORKDIR / f"danawa_쿠팡_결과_{datetime.now():%Y%m%d_%H%M}.xlsx"


def _only_digits(s): 
    return re.sub(r"[^\d]", "", s or "")

def get_driver():
    from webdriver_manager.chrome import ChromeDriverManager
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver


def fetch_wow_prices_selenium(driver, pcodes):
    """단일 Selenium 인스턴스로 여러 상품코드 와우가격 보정"""
    wow_map = {}
    for pcode in pcodes:
        try:
            url = f"https://prod.danawa.com/info/?pcode={pcode}"
            driver.get(url)
            WebDriverWait(driver, 8).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#lowPriceCompanyArea"))
            )
            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")
            text = soup.get_text(" ", strip=True)
            match = re.search(r"와우할인가\s*([\d,]+)\s*원", text)
            if match:
                wow_map[pcode] = match.group(1).replace(",", "")
        except Exception:
            continue
    return wow_map


# -----------------------------
# 🔹 HTML 파싱 (정적)
# -----------------------------
def _is_coupang_logo(el):
    if el is None:
        return False
    img = el.select_one("img[alt]")
    if img and "쿠팡" in (img.get("alt") or ""):
        return True
    aria = el.get("aria-label") or ""
    if "쿠팡" in aria:
        return True
    text_logo = el.select_one(".text__logo")
    if text_logo and "쿠팡" in text_logo.get_text(strip=True):
        return True
    return False


def _has_wow_hint(text):
    return "와우" in text or "WOW" in text.upper()


def _has_card_hint(text):
    for k in ["카드", "청구", "할인", "삼성", "롯데", "하나", "현대"]:
        if k in text:
            return True
    return False


def _pick_prices_in(el):
    prices = []
    for sel in [".text__num", ".price_num strong", ".txt_prc strong", ".prc strong"]:
        for numel in el.select(sel):
            num = _only_digits(numel.get_text(strip=True))
            if num:
                prices.append(int(num))
    return prices


def parse_product_html(html: str, pcode: str) -> dict:
    soup = BeautifulSoup(html, "html.parser")
    row = {"상품코드": pcode, "상품명": "이름없음", "쿠팡": "X", "쿠팡와우": "X", "쿠팡카드혜택가": "X"}

    tag = soup.select_one("meta[property='og:title']")
    if tag and tag.get("content"):
        row["상품명"] = tag["content"].strip()
    else:
        alt = soup.select_one(".prod_tit, h3.tit")
        if alt:
            row["상품명"] = alt.get_text(strip=True)

    for li in soup.select("ul.list__mall-price > li.list-item"):
        logo = li.select_one(".box__logo, .box__logo-wrap .box__logo")
        if not _is_coupang_logo(logo):
            continue
        txt = li.get_text(" ", strip=True)
        prices = _pick_prices_in(li)
        if not prices:
            continue
        price = min(prices)
        if _has_card_hint(txt):
            row["쿠팡카드혜택가"] = str(price)
        elif not _has_wow_hint(txt):
            row["쿠팡"] = str(price)
        # 와우는 Selenium에서 따로 보정
    return row


# -----------------------------
# 🔹 비동기 병렬 크롤링 (정적)
# -----------------------------
async def fetch_one(session, pcode):
    url = f"https://prod.danawa.com/info/?pcode={pcode}"
    try:
        async with session.get(url, timeout=10) as r:
            html = await r.text()
            return parse_product_html(html, pcode)
    except Exception:
        return {"상품코드": pcode, "상품명": "에러", "쿠팡": "X", "쿠팡와우": "X", "쿠팡카드혜택가": "X"}


async def run_async_crawler(codes):
    results_map = {}
    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = [fetch_one(session, c) for c in codes]
        for coro in asyncio.as_completed(tasks):
            row = await coro
            results_map[row["상품코드"]] = row
    return results_map


# -----------------------------
# 🔹 실행 메인
# -----------------------------
def run_requests_crawler():
    try:
        print(f"[{datetime.now()}] Danawa 크롤링 시작")
        df = pd.read_excel(INPUT_PATH)
        df.columns = [str(c).strip() for c in df.columns]
        if "상품코드" not in df.columns:
            df.rename(columns={df.columns[0]: "상품코드"}, inplace=True)

        codes = df["상품코드"].dropna().astype(str).str.replace(r"\.0$", "", regex=True).tolist()
        model_by_code = {}
        if "모델명" in df.columns:
            for c, m in zip(df["상품코드"].astype(str), df["모델명"].astype(str).fillna("")):
                model_by_code[str(c).replace(".0","").strip()] = m

        # ✅ 정적 병렬 크롤링
        results_map = asyncio.run(run_async_crawler(codes))

        # 상품명 보완 (엑셀 모델명 사용)
        for c, r in results_map.items():
            if c in model_by_code and r["상품명"] in ("이름없음", "에러"):
                r["상품명"] = model_by_code[c]

        # ✅ 와우가격 보정
        need_wow = [c for c, r in results_map.items() if r.get("쿠팡와우") in ("X", "", None)]
        print(f"🟡 와우가격 보정 대상 {len(need_wow)}개")
        if need_wow:
            driver = get_driver()
            wow_map = fetch_wow_prices_selenium(driver, need_wow)
            driver.quit()
            for c, w in wow_map.items():
                results_map[c]["쿠팡와우"] = w

        # ✅ DataFrame 정리
        results = [results_map[c] for c in codes if c in results_map]
        df_out = pd.DataFrame(results).fillna("X")
        nums = pd.DataFrame({
            "쿠팡": pd.to_numeric(df_out["쿠팡"], errors="coerce"),
            "쿠팡와우": pd.to_numeric(df_out["쿠팡와우"], errors="coerce"),
            "쿠팡카드혜택가": pd.to_numeric(df_out["쿠팡카드혜택가"], errors="coerce"),
        })
        df_out["최저가"] = nums.min(axis=1).map(lambda x: "X" if pd.isna(x) else str(int(x)))
        df_out.to_excel(OUTPUT_PATH, index=False)

        # ✅ 하이라이트 표시
        wb = load_workbook(OUTPUT_PATH)
        ws = wb.active
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        header = [cell.value for cell in ws[1]]
        for idx, name in enumerate(header, start=1):
            if name in TARGET_COLS:
                for r in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=idx, max_col=idx):
                    for cell in r:
                        cell.fill = yellow
        wb.save(OUTPUT_PATH)
        print(f"✅ 결과 파일 생성: {OUTPUT_PATH}")

    except Exception as e:
        print(traceback.format_exc())
        print(f"❌ 오류 발생: {e}")


if __name__ == "__main__":
    run_requests_crawler()
