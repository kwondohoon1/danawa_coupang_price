# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Mq30bavMMGFxHgWOOCEJpdgMXmn4L3i
"""

import os, re, io, time, tempfile, traceback
from pathlib import Path
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# ===============================================
# âš¡ Danawa ì¿ íŒ¡ í¬ë¡¤ëŸ¬ (Selenium 100%)
# ===============================================

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
TARGET_COLS = ["ì¿ íŒ¡", "ì¿ íŒ¡ì™€ìš°", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"]

BASE = Path(__file__).parent
INPUT_PATH = BASE / "ìƒí’ˆì½”ë“œëª©ë¡.xlsx"
OUTPUT_PATH = BASE / f"danawa_ì¿ íŒ¡_ì •í™•ë²„ì „_{datetime.now():%Y%m%d_%H%M}.xlsx"

def _only_digits(s): return re.sub(r"[^\d]", "", s or "")

# -----------------------------
# ğŸ”¹ Chrome ë“œë¼ì´ë²„ ìƒì„±
# -----------------------------
def get_driver():
    from webdriver_manager.chrome import ChromeDriverManager
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

# -----------------------------
# ğŸ”¹ í˜ì´ì§€ íŒŒì‹± í•¨ìˆ˜
# -----------------------------
def parse_with_selenium(driver, pcode):
    """ë‹¨ì¼ ìƒí’ˆì½”ë“œì— ëŒ€í•´ Seleniumìœ¼ë¡œ ì™„ì „ ë¡œë”© í›„ HTML íŒŒì‹±"""
    url = f"https://prod.danawa.com/info/?pcode={pcode}"
    row = {"ìƒí’ˆì½”ë“œ": pcode, "ìƒí’ˆëª…": "ì´ë¦„ì—†ìŒ", "ì¿ íŒ¡": "X", "ì¿ íŒ¡ì™€ìš°": "X", "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€": "X"}
    try:
        driver.get(url)
        # í˜ì´ì§€ ì™„ì „ ë¡œë“œ ëŒ€ê¸°
        WebDriverWait(driver, 20).until(lambda d: d.execute_script("return document.readyState") == "complete")

        # ê°€ê²© ì„¹ì…˜ ë³´ì¼ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#lowPriceCompanyArea"))
        )

        # ì²œì²œíˆ ìŠ¤í¬ë¡¤í•´ì„œ ë™ì  ë¡œë”© ìœ ë„
        for _ in range(6):
            driver.execute_script("window.scrollBy(0, 500);")
            time.sleep(0.8)

        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")

        # ìƒí’ˆëª…
        title_tag = soup.select_one("meta[property='og:title']")
        if title_tag and title_tag.get("content"):
            row["ìƒí’ˆëª…"] = title_tag["content"].strip()
        else:
            alt = soup.select_one(".prod_tit, h3.tit")
            if alt:
                row["ìƒí’ˆëª…"] = alt.get_text(strip=True)

        # ê°€ê²© ì„¹ì…˜
        for li in soup.select("ul.list__mall-price > li.list-item"):
            text_all = li.get_text(" ", strip=True)
            prices = [int(_only_digits(p.get_text(strip=True))) for p in li.select(".text__num, .price_num strong, .txt_prc strong, .prc strong") if _only_digits(p.get_text(strip=True))]
            if not prices:
                continue
            price = min(prices)

            # ì¿ íŒ¡ ë¡œê³  í™•ì¸
            is_coupang = False
            logo = li.select_one(".box__logo, .box__logo-wrap .box__logo")
            if logo:
                if "ì¿ íŒ¡" in logo.get("aria-label", ""):
                    is_coupang = True
                img = logo.select_one("img[alt]")
                if img and "ì¿ íŒ¡" in (img.get("alt") or ""):
                    is_coupang = True
            if not is_coupang:
                continue

            # ë¶„ë¥˜
            if "ì™€ìš°" in text_all or "WOW" in text_all.upper():
                row["ì¿ íŒ¡ì™€ìš°"] = str(price)
            elif any(k in text_all for k in ["ì¹´ë“œ", "ì²­êµ¬", "í• ì¸", "ì‚¼ì„±", "ë¡¯ë°", "í•˜ë‚˜", "í˜„ëŒ€"]):
                row["ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"] = str(price)
            else:
                row["ì¿ íŒ¡"] = str(price)

        return row

    except Exception as e:
        print(f"[ì˜¤ë¥˜] {pcode} â†’ {e}")
        return row

# -----------------------------
# ğŸ”¹ ì „ì²´ ì‹¤í–‰
# -----------------------------
def run_requests_crawler():
    try:
        print(f"[{datetime.now()}] Danawa ì •í™•ë²„ì „ ì‹œì‘")
        df = pd.read_excel(INPUT_PATH)
        codes = df["ìƒí’ˆì½”ë“œ"].dropna().astype(str).tolist()
        driver = get_driver()

        results = []
        for idx, code in enumerate(codes, start=1):
            print(f"({idx}/{len(codes)}) ìˆ˜ì§‘ ì¤‘... {code}")
            row = parse_with_selenium(driver, code)
            results.append(row)

        driver.quit()

        df_out = pd.DataFrame(results).fillna("X")
        nums = pd.DataFrame({
            "ì¿ íŒ¡": pd.to_numeric(df_out["ì¿ íŒ¡"], errors="coerce"),
            "ì¿ íŒ¡ì™€ìš°": pd.to_numeric(df_out["ì¿ íŒ¡ì™€ìš°"], errors="coerce"),
            "ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€": pd.to_numeric(df_out["ì¿ íŒ¡ì¹´ë“œí˜œíƒê°€"], errors="coerce"),
        })
        df_out["ìµœì €ê°€"] = nums.min(axis=1).map(lambda x: "X" if pd.isna(x) else str(int(x)))

        df_out.to_excel(OUTPUT_PATH, index=False)

        wb = load_workbook(OUTPUT_PATH)
        ws = wb.active
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        header = [cell.value for cell in ws[1]]
        for idx, name in enumerate(header, start=1):
            if name in TARGET_COLS:
                for r in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=idx, max_col=idx):
                    for cell in r:
                        cell.fill = yellow
        wb.save(OUTPUT_PATH)
        print(f"âœ… ì™„ë£Œ: {OUTPUT_PATH}")
    except Exception as e:
        print(traceback.format_exc())
        print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    run_requests_crawler()
